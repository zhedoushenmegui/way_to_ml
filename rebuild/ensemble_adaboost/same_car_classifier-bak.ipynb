{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码参考<<机器学习实战>>\n",
    "### https://github.com/pbharrin/machinelearninginaction/blob/master/Ch07/adaboost.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mat, zeros, inf, ones, log, sign, multiply, dot, exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "project_path = os.path.abspath(os.path.join(os.path.dirname(os.path.abspath('.')), '../'))\n",
    "import sys\n",
    "sys.path.append(project_path)\n",
    "from util.visualization import draw_lines\n",
    "from util.visualization import draw_scatters\n",
    "from util.evaluate_process import classifier_evaluate\n",
    "from collections import Counter\n",
    "from sklearn.metrics import auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.visualization import draw_tree, tree_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_evaluate(target, pred, labels=None):\n",
    "    \"\"\"\n",
    "    二分类模型评估\n",
    "    :param labels:\n",
    "    :param target:\n",
    "    :param pred:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if labels is None:\n",
    "        positive, negative = 1, 0\n",
    "    else:\n",
    "        positive, negative = labels[0], labels[1]\n",
    "    df = pd.DataFrame({'target': list(target), 'pred': list(pred)})\n",
    "    recall = len(df[(df.target == positive) & (df.pred == positive)]) / len(df[df.target == positive])\n",
    "    precision = len(df[(df.target == positive) & (df.pred == positive)]) / len(df[df.pred == positive])\n",
    "    accuracy = len(df[df.target == df.pred]) / len(df)\n",
    "    f1score = 2 * recall * accuracy / (recall + accuracy)\n",
    "    ret = {\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1score,\n",
    "        'tp': len(df[(df.target == positive) & (df.pred == positive)]),\n",
    "        'fp': len(df[(df.target == negative) & (df.pred == positive)]),\n",
    "        'tn': len(df[(df.target == negative) & (df.pred == negative)]),\n",
    "        'fn': len(df[(df.target == positive) & (df.pred == negative)])\n",
    "    }\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 单层决策树作为基分类器\n",
    "def stump_classify(df, dimen, thresh_val, condition):  # just classify the data\n",
    "    rdf = df[[dimen]].copy()\n",
    "    if condition == 'lt':\n",
    "        return list(rdf[dimen].map(lambda x: 1 if x <= thresh_val else -1))\n",
    "    else:\n",
    "        return list(rdf[dimen].map(lambda x: 1 if x >  thresh_val else -1))\n",
    "    \n",
    "    \n",
    "def build_stump(df, labels, D=None):\n",
    "    \"\"\"\n",
    "    D 样本权重向量\n",
    "    \"\"\"\n",
    "    m, n = df.shape\n",
    "    if D is None:\n",
    "        D = np.array([1/m] * m)\n",
    "    n_steps = 10.0  # 特征值分成10份, 如果是离散值就先判断离散值的数量\n",
    "    bestStump = {}\n",
    "    bestClasEst = mat(zeros((m, 1)))\n",
    "    minError = inf  # init error sum, to +infinity\n",
    "    for feat in df.columns:\n",
    "        # loop over all dimensions\n",
    "        # 遍历所有特征\n",
    "        uniq_vals = set(df[feat])\n",
    "        if len(uniq_vals) >n_steps:\n",
    "            rangeMin = min(df[feat])\n",
    "            rangeMax = max(df[feat])\n",
    "            stepSize = (rangeMax - rangeMin) / n_steps\n",
    "            thresh_vals = [rangeMin + k * stepSize for k in range(int(n_steps) + 1)]\n",
    "        else:\n",
    "            thresh_vals = uniq_vals\n",
    "        for thresh_val in thresh_vals:  # loop over all range in current dimension\n",
    "            for condition in ['lt', 'gt']:  # go over less than and greater than\n",
    "                predictedVals = stump_classify(df, feat, thresh_val, condition)  # call stump classify with i, j, lessThan\n",
    "                errArr = [0 if p == l else 1 for p, l in zip(predictedVals, labels)]\n",
    "                weightedError = np.dot(D.T, errArr)  # 加权误差率\n",
    "                # print \"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" % (i, threshVal, inequal, weightedError)\n",
    "                if weightedError < minError:\n",
    "                    minError = weightedError\n",
    "                    bestClasEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = feat\n",
    "                    bestStump['thresh'] = thresh_val\n",
    "                    bestStump['condition'] = condition\n",
    "    return bestStump, minError, bestClasEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_sample_weight(row, alpha):\n",
    "    expon = -alpha * row.label * row.label_est\n",
    "    c = np.exp(expon)\n",
    "    return row.sample_weight * c\n",
    "\n",
    "def adaboost_fit(df, labels, n_estimators=40, random_state=None):\n",
    "    base_classifiers = []\n",
    "    m = len(df)\n",
    "    rdf = pd.DataFrame({\n",
    "        'label': labels,\n",
    "        'label_est': None,\n",
    "        'sample_weight':  [1/m] * m,  # 样本权重\n",
    "        'agg_label_est': [0] * m\n",
    "    })\n",
    "\n",
    "    for i in range(n_estimators):\n",
    "        best_stump, error, label_est = build_stump(df, labels, rdf.sample_weight)  # 调用基分类器\n",
    "        alpha = 0.5 * np.log((1.0 - error) / error)  # 基分类器权重\n",
    "        best_stump['alpha'] = alpha\n",
    "        base_classifiers.append(best_stump)  # store Stump Params in Array\n",
    "        #### 计算新的样本权重分布\n",
    "        rdf['label_est'] = label_est\n",
    "        # w => 𝑤(𝑚,𝑖)𝑒𝑥𝑝(−α𝑚𝑦𝑖𝐺𝑚(𝑥𝑖)) w 是个中间结果\n",
    "        rdf['w'] = rdf.apply(lambda row: cal_sample_weight(row, alpha), axis=1)\n",
    "        z = sum(rdf.w)\n",
    "        rdf['sample_weight'] = rdf.w.map(lambda x: x/z)\n",
    "        # calc training error of all classifiers, if this is 0 quit for loop early (use break)\n",
    "        # 已有模型的加权结果\n",
    "        rdf['agg_label_est'] = rdf.apply(lambda row: row.agg_label_est + alpha * row.label_est, axis=1)\n",
    "        agg_errors = len(rdf[rdf.agg_label_est.map(np.sign) != rdf.label])\n",
    "        agg_error_rate = agg_errors / m\n",
    "        print(i, \"total error: \", agg_error_rate)\n",
    "        if agg_error_rate == 0.0:\n",
    "            break\n",
    "    return base_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost_predict(df, base_models):\n",
    "    m = len(df)\n",
    "    rdf = pd.DataFrame({'agg_label_est': [0] * m})\n",
    "    for clf in base_models:\n",
    "        rdf['label_est'] = stump_classify(df, clf['dim'], clf['thresh'], clf['condition'])\n",
    "        rdf['agg_label_est'] = rdf.apply(lambda row: row.agg_label_est + clf['alpha'] * row.label_est, axis=1)\n",
    "    return sign(rdf.agg_label_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/preprocessed.samecar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [\n",
    "    'colorp1', 'colorp2', \n",
    "    'fuel_typep1', 'fuel_typep2','displacement_standard1', 'displacement_standard2',\n",
    "    'gearboxp1', 'gearboxp2', 'displacement_diff', 'displacement_diff_sparse',\n",
    "    'mile_diff', 'mile_diff_sparse', 'mile_diff_rate', 'mile_diff_rate_sparse',\n",
    "    'year_diff', 'year_diff_sparse', 'licensed_city_diff_sparse', 'title_diff', \n",
    "    'title_diff_sparse', 'register_time_diff', 'register_time_diff_sparse',\n",
    "    'is_import_diff_sparse', 'transfer_times_diff', 'transfer_times_diff_sparse'\n",
    "]\n",
    "# 只保留离散特征\n",
    "sparse_feats = [\n",
    "    'colorp1', 'colorp2', \n",
    "    'fuel_typep1', 'fuel_typep2','displacement_standard1', 'displacement_standard2',\n",
    "    'gearboxp1', 'gearboxp2', 'displacement_diff_sparse',\n",
    "    'mile_diff_sparse', 'mile_diff_rate_sparse',\n",
    "    'year_diff_sparse', 'licensed_city_diff_sparse', \n",
    "    'title_diff_sparse', 'register_time_diff_sparse',\n",
    "    'is_import_diff_sparse', 'transfer_times_diff_sparse'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8038, 2680)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_same'] = df.is_same.map(lambda x: -1 if x == 0 else 1)\n",
    "rdf = df[feats]\n",
    "X_train, X_test, y_train, y_test = train_test_split(rdf, df.is_same, test_size=0.25, random_state=10)\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 total error:  0.030480218959940283\n",
      "1 total error:  0.030480218959940283\n",
      "2 total error:  0.030480218959940283\n",
      "3 total error:  0.030480218959940283\n",
      "4 total error:  0.02338890271211744\n",
      "5 total error:  0.02363772082607614\n",
      "6 total error:  0.023886538940034834\n",
      "7 total error:  0.02363772082607614\n",
      "8 total error:  0.023886538940034834\n",
      "9 total error:  0.0230156755411794\n",
      "10 total error:  0.025006220452848966\n",
      "11 total error:  0.024384175167952226\n",
      "12 total error:  0.02562826573774571\n",
      "13 total error:  0.022518039313262007\n",
      "14 total error:  0.023264493655138094\n",
      "15 total error:  0.0230156755411794\n",
      "16 total error:  0.023140084598158746\n",
      "17 total error:  0.0227668574272207\n",
      "18 total error:  0.022518039313262007\n",
      "19 total error:  0.023762129883055486\n",
      "20 total error:  0.022518039313262007\n",
      "21 total error:  0.0227668574272207\n",
      "22 total error:  0.021771584971385916\n",
      "23 total error:  0.022020403085344614\n",
      "24 total error:  0.021771584971385916\n",
      "25 total error:  0.02152276685742722\n",
      "26 total error:  0.02164717591440657\n",
      "27 total error:  0.021895994028365263\n",
      "28 total error:  0.021149539686489176\n",
      "29 total error:  0.02164717591440657\n",
      "30 total error:  0.021273948743468524\n",
      "31 total error:  0.02164717591440657\n",
      "32 total error:  0.021273948743468524\n",
      "33 total error:  0.02164717591440657\n",
      "34 total error:  0.021149539686489176\n",
      "35 total error:  0.02164717591440657\n",
      "36 total error:  0.02102513062950983\n",
      "37 total error:  0.02164717591440657\n",
      "38 total error:  0.021273948743468524\n",
      "39 total error:  0.021895994028365263\n"
     ]
    }
   ],
   "source": [
    "models = adaboost_fit(X_train, y_train, n_estimators=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.9724770642201835,\n",
       " 'precision': 0.9614512471655329,\n",
       " 'accuracy': 0.9783582089552239,\n",
       " 'f1': 0.9754087717020136,\n",
       " 'tp': 848,\n",
       " 'fp': 34,\n",
       " 'tn': 1774,\n",
       " 'fn': 24}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = adaboost_predict(X_test, models)\n",
    "classifier_evaluate(y_test, pred, [1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
